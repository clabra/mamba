{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clabra/mamba/blob/test/Mamba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z_KvAnY3CNGv"
      },
      "outputs": [],
      "source": [
        "pip install causal-conv1d>=1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install mamba-ssm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yIa7Ph-CZ6X",
        "outputId": "eb25b3ea-3a46-43de-c4a6-875a3d08eb26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mamba-ssm\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.1)\n",
            "Collecting einops (from mamba-ssm)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323803485 sha256=cd8ee941b25398d90c135d3a180b5dc33e478c98ae4998b61749809beaff947a\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: einops, mamba-ssm\n",
            "Successfully installed einops-0.8.0 mamba-ssm-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone git+git://github.com/clabra/mamba.git\n",
        "!git clone https://github.com/clabra/mamba.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysJMcyNieVRW",
        "outputId": "49ee1fae-5ba1-47d4-b476-f6b951957d83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mamba'...\n",
            "remote: Enumerating objects: 550, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 550 (delta 0), reused 6 (delta 0), pack-reused 542\u001b[K\n",
            "Receiving objects: 100% (550/550), 1.49 MiB | 3.75 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%cd mamba\n",
        "!pwd\n",
        "!sudo python setup.py install\n",
        "%cd ../\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wFsgCVegraA",
        "outputId": "168e3aba-be70-44bf-9430-3b35c5335739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/mamba\n",
            "/content/mamba\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "\n",
            "torch.__version__  = 2.3.0+cu121\n",
            "\n",
            "\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mamba_ssm.egg-info\n",
            "writing mamba_ssm.egg-info/PKG-INFO\n",
            "writing dependency_links to mamba_ssm.egg-info/dependency_links.txt\n",
            "writing requirements to mamba_ssm.egg-info/requires.txt\n",
            "writing top-level names to mamba_ssm.egg-info/top_level.txt\n",
            "writing manifest file 'mamba_ssm.egg-info/SOURCES.txt'\n",
            "reading manifest file 'mamba_ssm.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'AUTHORS'\n",
            "writing manifest file 'mamba_ssm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm\n",
            "copying mamba_ssm/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/mamba2.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/mha.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/ssd_minimal.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/mamba_simple.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/mamba2_simple.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/mlp.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "copying mamba_ssm/modules/block.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/models\n",
            "copying mamba_ssm/models/mixer_seq_simple.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/models\n",
            "copying mamba_ssm/models/config_mamba.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/models\n",
            "copying mamba_ssm/models/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/models\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/ops\n",
            "copying mamba_ssm/ops/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops\n",
            "copying mamba_ssm/ops/selective_scan_interface.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/utils\n",
            "copying mamba_ssm/utils/hf.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/utils\n",
            "copying mamba_ssm/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/utils\n",
            "copying mamba_ssm/utils/generation.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/distributed\n",
            "copying mamba_ssm/distributed/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/distributed\n",
            "copying mamba_ssm/distributed/tensor_parallel.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/distributed\n",
            "copying mamba_ssm/distributed/distributed_utils.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/distributed\n",
            "creating build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/ssd_state_passing.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/layernorm_gated.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/softplus.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/ssd_chunk_state.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/ssd_combined.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/ssd_chunk_scan.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/layer_norm.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/ssd_bmm.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/__init__.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/selective_state_update.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "copying mamba_ssm/ops/triton/k_activations.py -> build/lib.linux-x86_64-cpython-310/mamba_ssm/ops/triton\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:418: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:428: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'selective_scan_cuda' extension\n",
            "creating /content/mamba/build/temp.linux-x86_64-cpython-310\n",
            "creating /content/mamba/build/temp.linux-x86_64-cpython-310/csrc\n",
            "creating /content/mamba/build/temp.linux-x86_64-cpython-310/csrc/selective_scan\n",
            "Emitting ninja build file /content/mamba/build/temp.linux-x86_64-cpython-310/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/10] c++ -MMD -MF /content/mamba/build/temp.linux-x86_64-cpython-310/csrc/selective_scan/selective_scan.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/mamba/csrc/selective_scan -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c -c /content/mamba/csrc/selective_scan/selective_scan.cpp -o /content/mamba/build/temp.linux-x86_64-cpython-310/csrc/selective_scan/selective_scan.o -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=selective_scan_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mamba Block\n",
        "The main module of this repository is the Mamba architecture block wrapping the selective SSM.\n",
        "\n",
        "Source: modules/mamba_simple.py.\n",
        "\n",
        "Usage:"
      ],
      "metadata": {
        "id": "dCpklpltCs5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "batch, length, dim = 2, 64, 16\n",
        "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
        "model = Mamba(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=16,  # SSM state expansion factor\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape"
      ],
      "metadata": {
        "id": "1bmv9GmFCdNM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mamba-2\n",
        "The Mamba-2 block is implemented at modules/mamba2.py.\n",
        "\n",
        "A simpler version is at modules/mamba2_simple.py\n",
        "\n",
        "The usage is similar to Mamba(-1):"
      ],
      "metadata": {
        "id": "ZW9jwy4cMNA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mamba_ssm import Mamba2\n",
        "model = Mamba2(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=64,  # SSM state expansion factor, typically 64 or 128\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        "    #headdim = None, # Gemini Suggestion -> Force headdim to 1 to make d_ssm divisible\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "POk7Fn2uC_MB",
        "outputId": "0312ec15-055d-422f-f1ac-194ed4f7d0c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-708ea4f320fe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmamba_ssm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMamba2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = Mamba2(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# This module uses roughly 3 * expand * d_model^2 parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Model dimension d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# SSM state expansion factor, typically 64 or 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mamba_ssm/modules/mamba2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, d_state, d_conv, conv_init, expand, headdim, d_ssm, ngroups, A_init_range, D_has_hdim, rmsnorm, norm_before_gate, dt_min, dt_max, dt_init_floor, dt_limit, bias, conv_bias, chunk_size, use_mem_eff_path, layer_idx, process_group, sequence_parallel, device, dtype)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mngroups\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngroups\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_ssm\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaddim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_ssm\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_has_hdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_has_hdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run zero-shot evaluations of models (corresponding to Table 3 of the paper), we use the lm-evaluation-harness library."
      ],
      "metadata": {
        "id": "C0ZPAOzhPO3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lm-eval==0.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjfzzaW8PMke",
        "outputId": "5cbd5c9a-8e93-4c3c-a2e3-a2aea31b10e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lm-eval==0.4.2 in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.32.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.20.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.10.1)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.11.1)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.13.1)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (4.41.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2) (10.1.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (3.9.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm-eval==0.4.2) (12.5.82)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval==0.4.2) (0.19.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm-eval==0.4.2) (23.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (67.7.2)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (0.1.6)\n",
            "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.2) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.2) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.2) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm-eval==0.4.2) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval==0.4.2) (8.1.7)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->lm-eval==0.4.2) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm-eval==0.4.2) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qrKwDewHPixQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reproduce the results on the mamba-2.8b-slimpj model reported in the blogposts:"
      ],
      "metadata": {
        "id": "bbT2YZ2UDCIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/mamba-130m --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande,openbookqa --device cuda --batch_size 256\n",
        "!python evals/lm_harness_eval.py --model hf --model_args pretrained=EleutherAI/pythia-160m --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande --trust_remote_code=True --"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySbtv8raUXp8",
        "outputId": "d4855822-9aa6-4b23-dc66-d812d1abd260"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-15 17:16:07.912065: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 17:16:07.912142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 17:16:08.021572: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 17:16:08.234070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 17:16:10.069327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 17.7MB/s]\n",
            "2024-07-15:17:16:14,374 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-07-15:17:16:21,774 INFO     [__main__.py:335] Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'winogrande']\n",
            "2024-07-15:17:16:21,774 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-07-15:17:16:21,781 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-07-15:17:16:21,821 INFO     [huggingface.py:162] Using device 'cuda'\n",
            "config.json: 100% 199/199 [00:00<00:00, 1.27MB/s]\n",
            "2024-07-15:17:16:22,376 INFO     [huggingface.py:414] Overrode HF model backend type, and using type 'causal'\n",
            "pytorch_model.bin: 100% 517M/517M [00:02<00:00, 236MB/s]\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 885kB/s]\n",
            "vocab.json: 100% 1.08M/1.08M [00:00<00:00, 4.58MB/s]\n",
            "merges.txt: 100% 457k/457k [00:00<00:00, 7.65MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 10.6MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 361kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 9.00k/9.00k [00:00<00:00, 25.9MB/s]\n",
            "Downloading data: 100% 190k/190k [00:00<00:00, 855kB/s]\n",
            "Downloading data: 100% 204k/204k [00:00<00:00, 1.47MB/s]\n",
            "Downloading data: 100% 55.7k/55.7k [00:00<00:00, 270kB/s]\n",
            "Generating train split: 100% 1119/1119 [00:00<00:00, 136643.36 examples/s]\n",
            "Generating test split: 100% 1172/1172 [00:00<00:00, 201497.14 examples/s]\n",
            "Generating validation split: 100% 299/299 [00:00<00:00, 93806.34 examples/s]\n",
            "Downloading data: 100% 331k/331k [00:00<00:00, 1.37MB/s]\n",
            "Downloading data: 100% 346k/346k [00:00<00:00, 1.74MB/s]\n",
            "Downloading data: 100% 86.1k/86.1k [00:00<00:00, 718kB/s]\n",
            "Generating train split: 100% 2251/2251 [00:00<00:00, 282811.48 examples/s]\n",
            "Generating test split: 100% 2376/2376 [00:00<00:00, 341910.53 examples/s]\n",
            "Generating validation split: 100% 570/570 [00:00<00:00, 186806.79 examples/s]\n",
            "Downloading builder script: 100% 4.36k/4.36k [00:00<00:00, 15.9MB/s]\n",
            "Downloading metadata: 100% 2.53k/2.53k [00:00<00:00, 13.0MB/s]\n",
            "Downloading readme: 100% 6.84k/6.84k [00:00<00:00, 21.8MB/s]\n",
            "The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Downloading data: 47.5MB [00:00, 72.4MB/s]\n",
            "Downloading data: 11.8MB [00:00, 68.4MB/s]\n",
            "Downloading data: 12.2MB [00:00, 68.8MB/s]\n",
            "Generating train split: 100% 39905/39905 [00:04<00:00, 8898.40 examples/s]\n",
            "Generating test split: 100% 10003/10003 [00:01<00:00, 8660.47 examples/s]\n",
            "Generating validation split: 100% 10042/10042 [00:01<00:00, 6049.32 examples/s]\n",
            "Map: 100% 39905/39905 [00:07<00:00, 5159.79 examples/s]\n",
            "Map: 100% 10042/10042 [00:02<00:00, 3698.48 examples/s]\n",
            "Downloading data: 100% 1.16M/1.16M [00:00<00:00, 8.54MB/s]\n",
            "Generating test split: 100% 5153/5153 [00:00<00:00, 353180.74 examples/s]\n",
            "2024-07-15:17:17:11,459 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-07-15:17:17:11,459 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "Downloading readme: 100% 9.06k/9.06k [00:00<00:00, 25.0MB/s]\n",
            "Downloading data: 100% 496k/496k [00:00<00:00, 2.44MB/s]\n",
            "Downloading data: 100% 58.2k/58.2k [00:00<00:00, 247kB/s]\n",
            "Downloading data: 100% 55.5k/55.5k [00:00<00:00, 275kB/s]\n",
            "Generating train split: 100% 4957/4957 [00:00<00:00, 418560.69 examples/s]\n",
            "Generating validation split: 100% 500/500 [00:00<00:00, 168975.26 examples/s]\n",
            "Generating test split: 100% 500/500 [00:00<00:00, 176231.26 examples/s]\n",
            "Downloading builder script: 100% 5.36k/5.36k [00:00<00:00, 16.8MB/s]\n",
            "Downloading readme: 100% 8.41k/8.41k [00:00<00:00, 24.9MB/s]\n",
            "The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Downloading data: 100% 1.82M/1.82M [00:00<00:00, 65.8MB/s]\n",
            "Downloading data: 100% 815k/815k [00:00<00:00, 18.9MB/s]\n",
            "Generating train split: 100% 16113/16113 [00:00<00:00, 21674.17 examples/s]\n",
            "Generating test split: 100% 3084/3084 [00:00<00:00, 23644.78 examples/s]\n",
            "Generating validation split: 100% 1838/1838 [00:00<00:00, 22386.77 examples/s]\n",
            "Downloading builder script: 100% 5.65k/5.65k [00:00<00:00, 21.6MB/s]\n",
            "Downloading readme: 100% 9.97k/9.97k [00:00<00:00, 26.3MB/s]\n",
            "The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Downloading data: 100% 3.40M/3.40M [00:00<00:00, 41.4MB/s]\n",
            "Generating train split: 100% 40398/40398 [00:01<00:00, 21589.46 examples/s]\n",
            "Generating test split: 100% 1767/1767 [00:00<00:00, 23371.35 examples/s]\n",
            "Generating validation split: 100% 1267/1267 [00:00<00:00, 22944.73 examples/s]\n",
            "2024-07-15:17:17:36,706 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 70134.79it/s]\n",
            "2024-07-15:17:17:36,767 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
            "100% 1838/1838 [00:02<00:00, 763.87it/s]\n",
            "2024-07-15:17:17:39,237 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
            "100% 500/500 [00:00<00:00, 1808.98it/s]\n",
            "2024-07-15:17:17:39,543 INFO     [task.py:395] Building contexts for lambada_openai on rank 0...\n",
            "100% 5153/5153 [00:11<00:00, 440.20it/s]\n",
            "2024-07-15:17:17:51,326 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
            "100% 10042/10042 [00:04<00:00, 2241.64it/s]\n",
            "2024-07-15:17:17:56,959 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
            "100% 2376/2376 [00:04<00:00, 579.67it/s]\n",
            "2024-07-15:17:18:01,224 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
            "100% 1172/1172 [00:01<00:00, 959.61it/s]\n",
            "2024-07-15:17:18:02,521 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 1/67719 [00:09<186:00:50,  9.89s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 234, in simple_evaluate\n",
            "    results = evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 373, in evaluate\n",
            "    resps = getattr(lm, reqtype)(cloned_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/api/model.py\", line 329, in loglikelihood\n",
            "    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 1032, in _loglikelihood_tokens\n",
            "    multi_logits = F.log_softmax(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 1974, in log_softmax\n",
            "    ret = input.log_softmax(dim)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.07 GiB. GPU \n",
            "Running loglikelihood requests:   0% 257/67719 [00:11<50:28, 22.27it/s]  \n",
            "python3: can't open file '/content/evals/lm_harness_eval.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/mamba-2.8b-slimpj --tasks boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa,race,truthfulqa_mc2 --device cuda --batch_size 256\n",
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/mamba-2.8b-slimpj --tasks mmlu --num_fewshot 5 --device cuda --batch_size"
      ],
      "metadata": {
        "id": "AI1qtsdlPo7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e44bd6-4ab7-48c8-adfc-e6a4f771273d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-15 17:20:52.684258: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 17:20:52.684327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 17:20:52.685924: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 17:20:52.694237: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 17:20:53.955539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-15:17:20:58,544 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-07-15:17:21:04,659 INFO     [__main__.py:335] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'openbookqa', 'piqa', 'race', 'truthfulqa_mc2', 'winogrande']\n",
            "2024-07-15:17:21:04,659 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-07-15:17:21:04,660 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-07-15:17:21:04,701 INFO     [huggingface.py:162] Using device 'cuda'\n",
            "config.json: 100% 200/200 [00:00<00:00, 966kB/s]\n",
            "2024-07-15:17:21:05,233 INFO     [huggingface.py:414] Overrode HF model backend type, and using type 'causal'\n",
            "pytorch_model.bin: 100% 11.1G/11.1G [03:19<00:00, 55.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run evaluations on Mamba-2 models, simply replace the model names:"
      ],
      "metadata": {
        "id": "xp3fRVFcbrOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/mamba2-2.7b --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande,openbookqa --device cuda --batch_size 256\n",
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/transformerpp-2.7b --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande,openbookqa --device cuda --batch_size 256\n",
        "!lm_eval --model mamba_ssm --model_args pretrained=state-spaces/mamba2attn-2.7b --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande,openbookqa --device cuda --batch_size 256"
      ],
      "metadata": {
        "id": "8ICGUOwcPuVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498a1488-5150-46e4-fe76-ee7ba73bdceb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-15 17:27:07.765591: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 17:27:07.766427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 17:27:07.883601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 17:27:08.119441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 17:27:10.535120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-15:17:27:17,533 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-07-15:17:27:25,232 INFO     [__main__.py:335] Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'winogrande']\n",
            "2024-07-15:17:27:25,232 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-07-15:17:27:25,237 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-07-15:17:27:25,278 INFO     [huggingface.py:162] Using device 'cuda'\n",
            "config.json: 100% 331/331 [00:00<00:00, 1.94MB/s]\n",
            "2024-07-15:17:27:26,151 INFO     [huggingface.py:414] Overrode HF model backend type, and using type 'causal'\n",
            "pytorch_model.bin: 100% 5.41G/5.41G [00:51<00:00, 105MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-07-15:17:28:53,481 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-07-15:17:28:53,481 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-07-15:17:29:02,603 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 82640.28it/s]\n",
            "2024-07-15:17:29:02,665 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
            "100% 1838/1838 [00:01<00:00, 950.90it/s]\n",
            "2024-07-15:17:29:04,664 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
            "100% 500/500 [00:00<00:00, 1826.27it/s]\n",
            "2024-07-15:17:29:04,968 INFO     [task.py:395] Building contexts for lambada_openai on rank 0...\n",
            "100% 5153/5153 [00:12<00:00, 419.25it/s]\n",
            "2024-07-15:17:29:17,340 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
            "100% 10042/10042 [00:05<00:00, 1830.73it/s]\n",
            "2024-07-15:17:29:24,086 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
            "100% 2376/2376 [00:02<00:00, 809.10it/s]\n",
            "2024-07-15:17:29:27,252 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
            "100% 1172/1172 [00:01<00:00, 972.45it/s]\n",
            "2024-07-15:17:29:28,539 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/67719 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 234, in simple_evaluate\n",
            "    results = evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 373, in evaluate\n",
            "    resps = getattr(lm, reqtype)(cloned_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/api/model.py\", line 329, in loglikelihood\n",
            "    return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 1032, in _loglikelihood_tokens\n",
            "    multi_logits = F.log_softmax(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 1974, in log_softmax\n",
            "    ret = input.log_softmax(dim)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.78 GiB. GPU \n",
            "Running loglikelihood requests:   0% 0/67719 [01:25<?, ?it/s]\n",
            "2024-07-15 17:31:36.784897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 17:31:36.784962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 17:31:36.791301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 17:31:36.810304: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 17:31:38.888229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-15:17:31:44,336 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-07-15:17:31:52,031 INFO     [__main__.py:335] Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'winogrande']\n",
            "2024-07-15:17:31:52,031 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-07-15:17:31:52,036 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-07-15:17:31:52,076 INFO     [huggingface.py:162] Using device 'cuda'\n",
            "config.json: 100% 853/853 [00:00<00:00, 5.02MB/s]\n",
            "2024-07-15:17:31:52,667 INFO     [huggingface.py:414] Overrode HF model backend type, and using type 'causal'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 164, in simple_evaluate\n",
            "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/api/model.py\", line 133, in create_from_arg_string\n",
            "    return cls(**args, **args2)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/mamba_lm.py\", line 56, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 201, in __init__\n",
            "    self._create_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/mamba_lm.py\", line 97, in _create_model\n",
            "    self._model = MambaLMHeadModel.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 290, in from_pretrained\n",
            "    model = cls(config, device=device, dtype=dtype, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 241, in __init__\n",
            "    self.backbone = MixerModel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 153, in __init__\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 154, in <listcomp>\n",
            "    create_block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 73, in create_block\n",
            "    block = Block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/modules/block.py\", line 30, in __init__\n",
            "    self.mixer = mixer_cls(dim)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/modules/mha.py\", line 94, in __init__\n",
            "    assert RotaryEmbedding is not None, \"rotary requires flash_attn to be installed\"\n",
            "AssertionError: rotary requires flash_attn to be installed\n",
            "2024-07-15 17:31:57.483982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-15 17:31:57.484038: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-15 17:31:57.485370: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-15 17:31:57.492687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-15 17:31:59.095620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-15:17:32:03,113 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-07-15:17:32:09,015 INFO     [__main__.py:335] Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'winogrande']\n",
            "2024-07-15:17:32:09,015 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-07-15:17:32:09,017 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-07-15:17:32:09,057 INFO     [huggingface.py:162] Using device 'cuda'\n",
            "config.json: 100% 599/599 [00:00<00:00, 2.57MB/s]\n",
            "2024-07-15:17:32:09,625 INFO     [huggingface.py:414] Overrode HF model backend type, and using type 'causal'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 164, in simple_evaluate\n",
            "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/api/model.py\", line 133, in create_from_arg_string\n",
            "    return cls(**args, **args2)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/mamba_lm.py\", line 56, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 201, in __init__\n",
            "    self._create_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/mamba_lm.py\", line 97, in _create_model\n",
            "    self._model = MambaLMHeadModel.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 290, in from_pretrained\n",
            "    model = cls(config, device=device, dtype=dtype, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 241, in __init__\n",
            "    self.backbone = MixerModel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 153, in __init__\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 154, in <listcomp>\n",
            "    create_block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/models/mixer_seq_simple.py\", line 73, in create_block\n",
            "    block = Block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/modules/block.py\", line 30, in __init__\n",
            "    self.mixer = mixer_cls(dim)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mamba_ssm/modules/mha.py\", line 94, in __init__\n",
            "    assert RotaryEmbedding is not None, \"rotary requires flash_attn to be installed\"\n",
            "AssertionError: rotary requires flash_attn to be installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "The script benchmarks/benchmark_generation_mamba_simple.py\n",
        "\n",
        "autoloads a model from the Hugging Face Hub,\n",
        "generates completions of a user-specified prompt,\n",
        "benchmarks the inference speed of this generation.\n",
        "Other configurable options include the top-p (nucleus sampling) probability, and the softmax temperature."
      ],
      "metadata": {
        "id": "aZSsLq8MP8v5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples\n",
        "To test generation latency (e.g. batch size = 1) with different sampling strategies:"
      ],
      "metadata": {
        "id": "ulvCJ769dQ2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"state-spaces/mamba-2.8b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --topp 0.9 --temperature 0.7 --repetition-penalty 1.2"
      ],
      "metadata": {
        "id": "GcJc0ZbURjgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3263df0d-9456-4b1f-c0e8-679c8714996d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/benchmarks/benchmark_generation_mamba_simple.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"EleutherAI/pythia-2.8b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --topp 0.9 --temperature 0.7 --repetition-penalty 1.2\n",
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"state-spaces/mamba-2.8b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --minp 0.05 --topk 0 --temperature 0.7 --repetition-penalty 1.2"
      ],
      "metadata": {
        "id": "BS_qSfGgtqhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test generation throughput with random prompts (e.g. large batch size):\n",
        "\n"
      ],
      "metadata": {
        "id": "fXFzV2oSRkuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"state-spaces/mamba-2.8b\" --batch 64\n",
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"EleutherAI/pythia-2.8b\" --batch 64"
      ],
      "metadata": {
        "id": "6SVZ91piRoJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y2aK3sKtRp6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Mamba-2, you just need to change the model name:"
      ],
      "metadata": {
        "id": "muDvc5qWRs--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python benchmarks/benchmark_generation_mamba_simple.py --model-name \"state-spaces/mamba2-2.7b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --topp 0.9 --temperature 0.7 --repetition-penalty 1.2"
      ],
      "metadata": {
        "id": "t03v7dRsRtmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GrJClnKiRvJy"
      }
    }
  ]
}